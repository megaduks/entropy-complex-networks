{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import wget\n",
    "import tarfile\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy, scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "\n",
    "from sklearn import preprocessing, linear_model\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "from networkentropy import network_energy as ne\n",
    "import time\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_avalilable_datasets_konect():\n",
    "    base_url = \"http://konect.uni-koblenz.de/downloads/\"\n",
    "    response = requests.get(base_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"An error occurred while getting data.\")\n",
    "    else:\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, \"html5lib\")\n",
    "        \n",
    "        table_html = soup.find(id='sort1')\n",
    "        \n",
    "        thead_html = table_html.find('thead')\n",
    "        tbody_html = table_html.find('tbody')\n",
    "         \n",
    "        column_names=[row.text for row in thead_html.findAll('td')]\n",
    "        rows = tbody_html.findAll('tr')\n",
    "        values=[[cell.get('href') for cell in value('a') if 'tsv' in cell.get('href')] for value in rows]\n",
    "        return [val[0].replace('.tar.bz2','').replace('tsv/','') for val in values]\n",
    "        \n",
    "def download_tsv_dataset_konect(network_name):\n",
    "    assert (network_name in read_avalilable_datasets_konect()),\"No network named: '\"+network_name+\"' found in Konect!\"\n",
    "    \n",
    "    tsv_file = 'http://konect.uni-koblenz.de/downloads/tsv/'+network_name+'.tar.bz2'\n",
    "    output_file=network_name+'.tar.bz2'\n",
    "    file_name = wget.download(tsv_file, out=output_file)\n",
    "    if os.path.exists(output_file):\n",
    "        shutil.move(file_name,output_file)\n",
    "    \n",
    "    return output_file\n",
    "    \n",
    "def unpack_tar_bz2_file(file_name):\n",
    "    tar = tarfile.open(\"./\"+file_name, \"r:bz2\")\n",
    "    output_dir=\"./network_\"+file_name.replace('.tar.bz2','')+\"/\"\n",
    "    tar.extractall(output_dir)\n",
    "    tar.close()\n",
    "    return output_dir\n",
    "\n",
    "def build_network_from_out_konect(network_name):\n",
    "    file_name=download_tsv_dataset_konect(network_name=network_name)\n",
    "    output_dir=unpack_tar_bz2_file(file_name)+network_name+\"/\"\n",
    "    files = [file for file in os.listdir(output_dir) if os.path.isfile(os.path.join(output_dir, file))]\n",
    "    out_file = [file for file in files if 'out.' in file]\n",
    "    assert (len(out_file)>0), 'No out. file in the directory.'\n",
    "    \n",
    "    #building network\n",
    "    G=nx.read_adjlist(output_dir+out_file[0], comments='%')\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Divide a list of nodes `l` in `n` chunks\"\"\"\n",
    "    l_c = iter(l)\n",
    "    while 1:\n",
    "        x = tuple(itertools.islice(l_c, n))\n",
    "        if not x:\n",
    "            return\n",
    "        yield x\n",
    "\n",
    "\n",
    "def _betmap(G_normalized_weight_sources_tuple):\n",
    "    \"\"\"Pool for multiprocess only accepts functions with one argument.\n",
    "    This function uses a tuple as its only argument. We use a named tuple for\n",
    "    python 3 compatibility, and then unpack it when we send it to\n",
    "    `betweenness_centrality_source`\n",
    "    \"\"\"\n",
    "    return nx.betweenness_centrality_source(*G_normalized_weight_sources_tuple)\n",
    "\n",
    "\n",
    "def betweenness_centrality_parallel(G, processes=None):\n",
    "    \"\"\"Parallel betweenness centrality  function\"\"\"\n",
    "    p = Pool(processes=processes)\n",
    "    node_divisor = len(p._pool) * 4\n",
    "    node_chunks = list(chunks(G.nodes(), int(G.order() / node_divisor)))\n",
    "    num_chunks = len(node_chunks)\n",
    "    bt_sc = p.map(_betmap,\n",
    "                  zip([G] * num_chunks,\n",
    "                      [True] * num_chunks,\n",
    "                      [None] * num_chunks,\n",
    "                      node_chunks))\n",
    "\n",
    "    # Reduce the partial solutions\n",
    "    bt_c = bt_sc[0]\n",
    "    for bt in bt_sc[1:]:\n",
    "        for n in bt:\n",
    "            bt_c[n] += bt[n]\n",
    "            \n",
    "    p.close()\n",
    "    return bt_c\n",
    "\n",
    "def calculate_betweenes(graph, k):\n",
    "    return nx.betweenness_centrality(graph, k=k)\n",
    "\n",
    "def calculate_randic_energy(graph):\n",
    "    results={}\n",
    "    for n in graph.nodes:\n",
    "        g = nx.ego_graph(G=graph, n=n, radius=1)\n",
    "        results[n]=ne.get_randic_energy(g)\n",
    "    return results\n",
    "\n",
    "def calculate_graph_energy(graph):\n",
    "    time_evaluation={}\n",
    "    time_evaluation['ego']=0\n",
    "    time_evaluation['graph_energy']=0\n",
    "     \n",
    "    results={}\n",
    "    for n in graph.nodes:\n",
    "        start = time.clock()\n",
    "        g = nx.ego_graph(G=graph, n=n, radius=1)\n",
    "        time_evaluation['ego']=time_evaluation['ego']+(time.clock() - start)\n",
    "        start = time.clock()\n",
    "        results[n]=ne.get_graph_energy(g)\n",
    "        time_evaluation['graph_energy']=time_evaluation['graph_energy']+(time.clock() - start)\n",
    "    return results, time_evaluation\n",
    "\n",
    "def calculate_graph_energy_numpy(graph):\n",
    "    results={}\n",
    "    for n in graph.nodes:\n",
    "        g = nx.ego_graph(G=graph, n=n, radius=1)\n",
    "        results[n]=get_graph_energy_numpy(g)\n",
    "    return results\n",
    "\n",
    "def get_graph_energy_numpy(G):\n",
    "    M = nx.adjacency_matrix(G).todense()\n",
    "    graph_energy = np.abs(np.linalg.eigvals(M).real).sum()\n",
    "    return graph_energy\n",
    "\n",
    "def normalize_df_column(df_column):\n",
    "    x = df_column.values.astype(float)\n",
    "    min_max_scaler = skl.preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x.reshape(-1, 1))\n",
    "    return x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks_names=['moreno_beach',\n",
    " 'moreno_bison',\n",
    " 'moreno_blogs',\n",
    " 'moreno_cattle',\n",
    " 'moreno_crime',\n",
    " 'moreno_health',\n",
    " 'moreno_hens',\n",
    " 'moreno_highschool',\n",
    " 'moreno_innovation',\n",
    " 'moreno_kangaroo',\n",
    " 'moreno_lesmis',\n",
    " 'moreno_mac',\n",
    " 'moreno_names',\n",
    " 'moreno_oz',\n",
    " 'moreno_propro',\n",
    " 'moreno_rhesus',\n",
    " 'moreno_sampson',\n",
    " 'moreno_seventh',\n",
    " 'moreno_sheep',\n",
    " 'moreno_taro',\n",
    " 'moreno_train',\n",
    " 'moreno_vdb',\n",
    " 'moreno_zebra',\n",
    " 'brunson_club-membership',\n",
    " 'brunson_southern-women',\n",
    " 'brunson_corporate-leadership',\n",
    " 'brunson_revolution',\n",
    " 'brunson_south-africa',\n",
    " 'ucidata-gama',\n",
    " 'ucidata-zachary',\n",
    " 'opsahl-collaboration',\n",
    " 'opsahl-openflights',\n",
    " 'opsahl-powergrid',\n",
    " 'opsahl-southernwomen',\n",
    " 'opsahl-ucforum',\n",
    " 'opsahl-ucsocial',\n",
    " 'opsahl-usairport',\n",
    " 'contiguous-usa',\n",
    " 'dolphins',\n",
    " 'adjnoun_adjacency',\n",
    " 'mit',\n",
    " 'foodweb-baydry',\n",
    " 'foodweb-baywet',\n",
    " 'sociopatterns-hypertext',\n",
    " 'sociopatterns-infectious',\n",
    " 'radoslaw_email',\n",
    " 'maayan-foodweb',\n",
    " 'arenas-jazz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n"
     ]
    }
   ],
   "source": [
    "networks=[]\n",
    "for network_name in tqdm(networks_names):\n",
    "    networks.append(build_network_from_out_konect(network_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n"
     ]
    }
   ],
   "source": [
    "real_data_measures=pd.DataFrame(columns=['node', 'value_type','value','network'])\n",
    "\n",
    "for i in tqdm(range(len(networks))):\n",
    "    G = networks[i]\n",
    "    \n",
    "    be=calculate_betweenes(G,k=None)\n",
    "    tmp_df=pd.DataFrame({'node': [i[0] for i in be.items()],\n",
    "                         'value_type': ['betweenness' for i in be.items()],\n",
    "                         'value': [i[1] for i in be.items()],\n",
    "                         'network': [networks_names[i] for j in be.items()]\n",
    "                        })\n",
    "    tmp_df['value']=normalize_df_column(tmp_df['value'])\n",
    "    real_data_measures=pd.concat([real_data_measures,tmp_df])\n",
    "        \n",
    "        \n",
    "    re=calculate_randic_energy(G)\n",
    "    tmp_df=pd.DataFrame({'node': [i[0] for i in re.items()],\n",
    "                         'value_type': ['randic' for i in re.items()],\n",
    "                         'value': [i[1] for i in re.items()],\n",
    "                         'network': [networks_names[i] for j in be.items()]\n",
    "                        })\n",
    "    tmp_df['value']=normalize_df_column(tmp_df['value'])\n",
    "    real_data_measures=pd.concat([real_data_measures,tmp_df])\n",
    "\n",
    "    ge,_=calculate_graph_energy(G)\n",
    "    tmp_df=pd.DataFrame({'node': [i[0] for i in ge.items()],\n",
    "                         'value_type': ['graph' for i in ge.items()],\n",
    "                         'value': [i[1] for i in ge.items()],\n",
    "                         'network': [networks_names[i] for j in be.items()]\n",
    "                        })\n",
    "    tmp_df['value']=normalize_df_column(tmp_df['value'])\n",
    "    real_data_measures=pd.concat([real_data_measures,tmp_df])\n",
    "    real_data_measures.to_pickle('./all_real_networks_calulated_betweenness_and_energy.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actor-collaboration',\n",
       " 'actor-movie',\n",
       " 'adjnoun_adjacency',\n",
       " 'advogato',\n",
       " 'amazon0601',\n",
       " 'amazon-ratings',\n",
       " 'arenas-email',\n",
       " 'arenas-jazz',\n",
       " 'arenas-meta',\n",
       " 'arenas-pgp',\n",
       " 'as20000102',\n",
       " 'as-caida20071105',\n",
       " 'as-skitter',\n",
       " 'bibsonomy-2ti',\n",
       " 'bibsonomy-2ui',\n",
       " 'bibsonomy-2ut',\n",
       " 'bookcrossing_full-rating',\n",
       " 'bookcrossing_rating',\n",
       " 'brunson_club-membership',\n",
       " 'brunson_southern-women',\n",
       " 'brunson_corporate-leadership',\n",
       " 'brunson_revolution',\n",
       " 'brunson_south-africa',\n",
       " 'ca-AstroPh',\n",
       " 'ca-cit-HepPh',\n",
       " 'ca-cit-HepTh',\n",
       " 'chess',\n",
       " 'cfinder-google',\n",
       " 'citeseer',\n",
       " 'citeulike-ti',\n",
       " 'citeulike-ui',\n",
       " 'citeulike-ut',\n",
       " 'cit-HepPh',\n",
       " 'cit-HepTh',\n",
       " 'com-amazon',\n",
       " 'com-dblp',\n",
       " 'com-youtube',\n",
       " 'contact',\n",
       " 'contiguous-usa',\n",
       " 'dblp-author',\n",
       " 'dblp-cite',\n",
       " 'dblp_coauthor',\n",
       " 'dbpedia-all',\n",
       " 'dbpedia-country',\n",
       " 'dbpedia-genre',\n",
       " 'dbpedia-link',\n",
       " 'dbpedia-location',\n",
       " 'dbpedia-occupation',\n",
       " 'dbpedia-producer',\n",
       " 'dbpedia-recordlabel',\n",
       " 'dbpedia-starring',\n",
       " 'dbpedia-team',\n",
       " 'dbpedia-writer',\n",
       " 'dbtropes-feature',\n",
       " 'delicious-ti',\n",
       " 'delicious-ui',\n",
       " 'delicious-ut',\n",
       " 'digg-friends',\n",
       " 'digg-votes',\n",
       " 'discogs_affiliation',\n",
       " 'discogs_genre',\n",
       " 'discogs_lgenre',\n",
       " 'discogs_lstyle',\n",
       " 'discogs_style',\n",
       " 'dnc-corecipient',\n",
       " 'dnc-temporalGraph',\n",
       " 'dolphins',\n",
       " 'douban',\n",
       " 'eat',\n",
       " 'edit-dewiki',\n",
       " 'edit-dewiktionary',\n",
       " 'edit-enwikibooks',\n",
       " 'edit-enwiki',\n",
       " 'edit-enwikinews',\n",
       " 'edit-enwikiquote',\n",
       " 'edit-enwiktionary',\n",
       " 'edit-eswiki',\n",
       " 'edit-frwikibooks',\n",
       " 'edit-frwiki',\n",
       " 'edit-frwikinews',\n",
       " 'edit-frwiktionary',\n",
       " 'edit-itwiki',\n",
       " 'ego-facebook',\n",
       " 'ego-gplus',\n",
       " 'ego-twitter',\n",
       " 'elec',\n",
       " 'email-EuAll',\n",
       " 'enron',\n",
       " 'epinions',\n",
       " 'epinions-rating',\n",
       " 'escorts',\n",
       " 'facebook-wosn-links',\n",
       " 'facebook-wosn-wall',\n",
       " 'flickrEdges',\n",
       " 'flickr-groupmemberships',\n",
       " 'flickr-growth',\n",
       " 'flickr-links',\n",
       " 'flixster',\n",
       " 'foldoc',\n",
       " 'foodweb-baydry',\n",
       " 'foodweb-baywet',\n",
       " 'friendster',\n",
       " 'github',\n",
       " 'gottron-excellent',\n",
       " 'gottron-reuters',\n",
       " 'gottron-trec',\n",
       " 'hyves',\n",
       " 'jester1',\n",
       " 'jester2',\n",
       " 'lasagne-yahoo',\n",
       " 'lastfm_band',\n",
       " 'lastfm_song',\n",
       " 'libimseti',\n",
       " 'link-dynamic-dewiki',\n",
       " 'link-dynamic-frwiki',\n",
       " 'link-dynamic-itwiki',\n",
       " 'link-dynamic-nlwiki',\n",
       " 'link-dynamic-plwiki',\n",
       " 'link-dynamic-simplewiki',\n",
       " 'linux',\n",
       " 'livejournal-groupmemberships',\n",
       " 'livejournal-links',\n",
       " 'livemocha',\n",
       " 'lkml_person-thread',\n",
       " 'lkml-reply',\n",
       " 'loc-brightkite_edges',\n",
       " 'loc-gowalla_edges',\n",
       " 'maayan-faa',\n",
       " 'maayan-figeys',\n",
       " 'maayan-foodweb',\n",
       " 'maayan-pdzbase',\n",
       " 'maayan-Stelzl',\n",
       " 'maayan-vidal',\n",
       " 'mit',\n",
       " 'moreno_beach',\n",
       " 'moreno_bison',\n",
       " 'moreno_blogs',\n",
       " 'moreno_cattle',\n",
       " 'moreno_crime',\n",
       " 'moreno_health',\n",
       " 'moreno_hens',\n",
       " 'moreno_highschool',\n",
       " 'moreno_innovation',\n",
       " 'moreno_kangaroo',\n",
       " 'moreno_lesmis',\n",
       " 'moreno_mac',\n",
       " 'moreno_names',\n",
       " 'moreno_oz',\n",
       " 'moreno_propro',\n",
       " 'moreno_rhesus',\n",
       " 'moreno_sampson',\n",
       " 'moreno_seventh',\n",
       " 'moreno_sheep',\n",
       " 'moreno_taro',\n",
       " 'moreno_train',\n",
       " 'moreno_vdb',\n",
       " 'moreno_zebra',\n",
       " 'movielens-100k_rating',\n",
       " 'movielens-10m_rating',\n",
       " 'movielens-10m_ti',\n",
       " 'movielens-10m_ui',\n",
       " 'movielens-10m_ut',\n",
       " 'movielens-1m',\n",
       " 'munmun_digg_reply',\n",
       " 'munmun_twitterex_ut',\n",
       " 'munmun_twitter_social',\n",
       " 'openflights',\n",
       " 'opsahl-collaboration',\n",
       " 'opsahl-openflights',\n",
       " 'opsahl-powergrid',\n",
       " 'opsahl-southernwomen',\n",
       " 'opsahl-ucforum',\n",
       " 'opsahl-ucsocial',\n",
       " 'opsahl-usairport',\n",
       " 'orkut-groupmemberships',\n",
       " 'orkut-links',\n",
       " 'p2p-Gnutella31',\n",
       " 'patentcite',\n",
       " 'petster-carnivore',\n",
       " 'petster-friendships-cat',\n",
       " 'petster-friendships-dog',\n",
       " 'petster-friendships-hamster',\n",
       " 'petster-hamster',\n",
       " 'pics_ti',\n",
       " 'pics_ui',\n",
       " 'pics_ut',\n",
       " 'prosper-loans',\n",
       " 'radoslaw_email',\n",
       " 'reactome',\n",
       " 'reuters',\n",
       " 'roadNet-CA',\n",
       " 'roadNet-PA',\n",
       " 'roadNet-TX',\n",
       " 'slashdot-threads',\n",
       " 'slashdot-zoo',\n",
       " 'soc-Epinions1',\n",
       " 'sociopatterns-hypertext',\n",
       " 'sociopatterns-infectious',\n",
       " 'soc-LiveJournal1',\n",
       " 'soc-pokec-relationships',\n",
       " 'stackexchange-stackoverflow',\n",
       " 'subelj_cora',\n",
       " 'subelj_euroroad',\n",
       " 'subelj_jdk',\n",
       " 'subelj_jung-j',\n",
       " 'tntp-ChicagoRegional',\n",
       " 'topology',\n",
       " 'trackers-trackers',\n",
       " 'trec-wt10g',\n",
       " 'twitter',\n",
       " 'twitter_mpi',\n",
       " 'ucidata-gama',\n",
       " 'ucidata-zachary',\n",
       " 'unicodelang',\n",
       " 'web-BerkStan',\n",
       " 'web-Google',\n",
       " 'web-NotreDame',\n",
       " 'web-Stanford',\n",
       " 'wikiconflict',\n",
       " 'wiki-en-cat',\n",
       " 'wikipedia-discussions-de',\n",
       " 'wikipedia-growth',\n",
       " 'wikipedia_link_de',\n",
       " 'wikipedia_link_en',\n",
       " 'wikipedia_link_fr',\n",
       " 'wikipedia_link_it',\n",
       " 'wikipedia_link_ja',\n",
       " 'wikipedia_link_pl',\n",
       " 'wikipedia_link_pt',\n",
       " 'wikipedia_link_ru',\n",
       " 'wikisigned-k2',\n",
       " 'wiki-Talk',\n",
       " 'wiki_talk_nl',\n",
       " 'wiki_talk_ar',\n",
       " 'wiki_talk_ru',\n",
       " 'wiki_talk_pt',\n",
       " 'wiki_talk_zh',\n",
       " 'wiki_talk_es',\n",
       " 'wiki_talk_it',\n",
       " 'wiki_talk_fr',\n",
       " 'wiki_talk_de',\n",
       " 'wiki_talk_en',\n",
       " 'wordnet-words',\n",
       " 'youtube-groupmemberships',\n",
       " 'youtube-links',\n",
       " 'youtube-u-growth',\n",
       " 'zhishi-baidu-internallink',\n",
       " 'zhishi-baidu-relatedpages',\n",
       " 'zhishi-hudong-internallink',\n",
       " 'zhishi-hudong-relatedpages']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_avalilable_datasets_konect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
